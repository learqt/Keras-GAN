{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WGAN-GP-Bac_à_sable.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/learqt/Keras-GAN/blob/master/WGAN_GP_Bac_%C3%A0_sable.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAyoWRhIBOtV",
        "colab_type": "text"
      },
      "source": [
        "Générer des fausses time series via WGAN-GP ( Wasserstein GAN - Gradient Penality)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQdQXZqIBKqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Packages\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import argparse\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import keras \n",
        "import numpy as np \n",
        "import time\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "mm_scaler = preprocessing.MinMaxScaler()\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Dense, Activation,Input,Reshape\n",
        "from keras import optimizers\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers import MaxPooling1D,Flatten\n",
        "from keras.layers import LeakyReLU,BatchNormalization,UpSampling1D\n",
        "from keras.optimizers import RMSprop\n",
        "from functools import partial\n",
        "from keras.layers.merge import _Merge\n",
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGW3AX7MC7mo",
        "colab_type": "code",
        "outputId": "5c23b6e2-d167-424f-d61c-b474ad5153b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "#Directory\n",
        "cwd=os.getcwd()\n",
        "cwd"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cUak3zktDbf",
        "colab_type": "code",
        "outputId": "6c9675ee-97a3-434e-b79a-4cf6dd8b410d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        }
      },
      "source": [
        "!pip install Keras==2.2.4\n",
        "!pip install tensorflow==1.15.2"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Keras==2.2.4 in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.4) (2.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.4) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.4) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.4) (1.18.2)\n",
            "Requirement already satisfied: tensorflow==1.15.2 in /usr/local/lib/python3.6/dist-packages (1.15.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (3.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (3.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.15.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.18.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.27.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.12.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.15.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.2.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.34.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.9.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.2) (46.1.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.2) (2.10.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQzQXdiixLO9",
        "colab_type": "code",
        "outputId": "3444fc30-2376-488d-b360-d5ce2575d03f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "cwd=os.getcwd()\n",
        "cwd"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znT2wfLsC-k5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#On utilise les données VIX\n",
        "my_data = pd.read_csv(cwd + '/vixcurrent.csv', header=1, index_col=0)\n",
        "vix_data = my_data.loc[:, 'VIX Close']\n",
        "vix_data=vix_data.pct_change()\n",
        "vix_data_arr = np.array((vix_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gav1J37K-4Py",
        "colab_type": "code",
        "outputId": "b878ebe7-c64c-432a-8594-ea2960e9cdea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "np.shape(vix_data_arr)"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3862,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcbuYYTXDAu0",
        "colab_type": "code",
        "outputId": "23d21b83-9eeb-4ed8-af01-f2da6242f0b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "#Graphs\n",
        "plt.plot(vix_data_arr)"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f96f0c24198>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 241
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD4CAYAAADsKpHdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORpzapVUNPS3",
        "colab_type": "text"
      },
      "source": [
        "Etapes d'WGAN-GP\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P83ZXL0Z009y",
        "colab_type": "code",
        "outputId": "8e66789b-53ce-484a-83ec-b93143f9d8ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "class RandomWeightedAverage(_Merge):\n",
        "    \"\"\"Provides a (random) weighted average between real and generated samples\"\"\"\n",
        "    def _merge_function(self, inputs):\n",
        "        alpha = K.random_uniform((32, 1, 1,1))\n",
        "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
        "\n",
        "class WGANGP():\n",
        "    def __init__(self):\n",
        "        self.img_rows = 99\n",
        "        self.img_cols = 30\n",
        "        #self.channels = 1\n",
        "        self.img_shape = (self.img_rows, self.img_cols)#,self.channels) #add channels ???\n",
        "        self.latent_dim = 50\n",
        "\n",
        "        # Following parameter and optimizer set as recommended in paper\n",
        "        self.n_critic = 5\n",
        "        optimizer = RMSprop(lr=0.00005)\n",
        "\n",
        "        # Build the generator and critic\n",
        "        self.generator = self.build_generator()\n",
        "        self.critic = self.build_critic()\n",
        "\n",
        "        #-------------------------------\n",
        "        # Construct Computational Graph\n",
        "        #       for the Critic\n",
        "        #-------------------------------\n",
        "\n",
        "        # Freeze generator's layers while training critic\n",
        "        self.generator.trainable = False\n",
        "\n",
        "        # Image input (real sample)\n",
        "        real_img = Input(shape=self.img_shape)\n",
        "\n",
        "        # Noise input\n",
        "        z_disc = Input(shape=(self.latent_dim,))\n",
        "        # Generate image based of noise (fake sample)\n",
        "        fake_img = self.generator(z_disc)\n",
        "\n",
        "        # Discriminator determines validity of the real and fake images\n",
        "        fake = self.critic(fake_img)\n",
        "        valid = self.critic(real_img)\n",
        "\n",
        "        # Construct weighted average between real and fake images\n",
        "        interpolated_img = RandomWeightedAverage()([real_img, fake_img])\n",
        "        # Determine validity of weighted sample\n",
        "        validity_interpolated = self.critic(interpolated_img)\n",
        "\n",
        "        # Use Python partial to provide loss function with additional\n",
        "        # 'averaged_samples' argument\n",
        "        partial_gp_loss = partial(self.gradient_penalty_loss,\n",
        "                          averaged_samples=interpolated_img)\n",
        "        partial_gp_loss.__name__ = 'gradient_penalty' # Keras requires function names\n",
        "\n",
        "        self.critic_model = Model(inputs=[real_img, z_disc],\n",
        "                            outputs=[valid, fake, validity_interpolated])\n",
        "        self.critic_model.compile(loss=[self.wasserstein_loss,\n",
        "                                              self.wasserstein_loss,\n",
        "                                              partial_gp_loss],\n",
        "                                        optimizer=optimizer,\n",
        "                                        loss_weights=[1, 1, 10])\n",
        "        #-------------------------------\n",
        "        # Construct Computational Graph\n",
        "        #         for Generator\n",
        "        #-------------------------------\n",
        "\n",
        "        # For the generator we freeze the critic's layers\n",
        "        self.critic.trainable = False\n",
        "        self.generator.trainable = True\n",
        "\n",
        "        # Sampled noise for input to generator\n",
        "        z_gen = Input(shape=(50,))\n",
        "        # Generate images based of noise\n",
        "        img = self.generator(z_gen)\n",
        "        # Discriminator determines validity\n",
        "        valid = self.critic(img)\n",
        "        # Defines generator model\n",
        "        self.generator_model = Model(z_gen, valid)\n",
        "        self.generator_model.compile(loss=self.wasserstein_loss, optimizer=optimizer)\n",
        "\n",
        "\n",
        "    def gradient_penalty_loss(self, y_true, y_pred, averaged_samples):\n",
        "        \"\"\"\n",
        "        Computes gradient penalty based on prediction and weighted real / fake samples\n",
        "        \"\"\"\n",
        "        gradients = K.gradients(y_pred, averaged_samples)[0]\n",
        "        # compute the euclidean norm by squaring ...\n",
        "        gradients_sqr = K.square(gradients)\n",
        "        #   ... summing over the rows ...\n",
        "        gradients_sqr_sum = K.sum(gradients_sqr,\n",
        "                                  axis=np.arange(1, len(gradients_sqr.shape)))\n",
        "        #   ... and sqrt\n",
        "        gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
        "        # compute lambda * (1 - ||grad||)^2 still for each single sample\n",
        "        gradient_penalty = K.square(1 - gradient_l2_norm)\n",
        "        # return the mean as loss over all the batch samples\n",
        "        return K.mean(gradient_penalty)\n",
        "\n",
        "\n",
        "    def wasserstein_loss(self, y_true, y_pred):\n",
        "        return K.mean(y_true * y_pred)\n",
        "\n",
        "    def build_generator(self):\n",
        "\n",
        "        # define model\n",
        "        model= Sequential() \n",
        "       \n",
        "        model.add(Dense(100,input_dim=self.latent_dim)) #diff between input_shape and input_dim\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "        model.add((Reshape((100,1))))\n",
        "\n",
        "        model.add(Conv1D(filters=32, kernel_size=3, padding='same'))\n",
        "        model.add (BatchNormalization())\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(UpSampling1D())\n",
        "        model.add(Conv1D(filters=32, kernel_size=3, padding='same'))\n",
        "        model.add (BatchNormalization())\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(UpSampling1D())\n",
        "        model.add(Conv1D(filters=32, kernel_size=3, padding='same'))\n",
        "        model.add (BatchNormalization())\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(UpSampling1D())\n",
        "        model.add(Conv1D(filters=32, kernel_size=3, padding='same'))\n",
        "        model.add (BatchNormalization())\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "        model.add(Flatten())\n",
        "\n",
        "        model.add(Dense(100))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "\n",
        "        noise = Input(shape=(self.latent_dim,))\n",
        "        img = model(noise)\n",
        "\n",
        "        return Model(noise, img)\n",
        "\n",
        "    def build_critic(self):\n",
        "\n",
        "        model= Sequential() \n",
        "        model.add((Reshape((99,30),input_shape=self.img_shape)))\n",
        "\n",
        "        model.add(Conv1D(filters=32, kernel_size=3, padding='same'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(MaxPooling1D(pool_size=2))\n",
        "        model.add(Conv1D(filters=32, kernel_size=3, padding='same'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(MaxPooling1D(pool_size=2))\n",
        "        model.add(Conv1D(filters=32, kernel_size=3, padding='same'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(MaxPooling1D(pool_size=2))\n",
        "        model.add(Flatten())\n",
        "\n",
        "        model.add(Dense(50))\n",
        "        model.add (BatchNormalization())\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dense(15))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dense(1))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        img = Input(shape=self.img_shape)\n",
        "        validity = model(img)\n",
        "\n",
        "        return Model(img, validity)\n",
        "\n",
        "    def train(self, epochs, batch_size, sample_interval=50):\n",
        "\n",
        "        #Load the dataset\n",
        "        my_data = pd.read_csv(cwd + '/vixcurrent.csv', header=1, index_col=0)\n",
        "        vix_data = my_data.loc[:, 'VIX Close']\n",
        "        vix_data=vix_data.pct_change() #transform in daily return\n",
        "        vix_data_arr = np.array((vix_data))\n",
        "\n",
        "        X = np.array([vix_data_arr[30*k:30 + 30*k] for k in range(0,int( vix_data.size/30))]) #shape:(99,30) --> sample of 30 days\n",
        "        X=X.astype(np.float32)\n",
        "        X_train = mm_scaler.fit_transform(X).reshape(-1, 1)\n",
        "        X_train = np.expand_dims(X_train)\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = -np.ones((batch_size, 1))\n",
        "        fake =  np.ones((batch_size, 1))\n",
        "        dummy = np.zeros((batch_size, 1)) # Dummy gt for gradient penalty\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            for _ in range(self.n_critic):\n",
        "\n",
        "                # ---------------------\n",
        "                #  Train Discriminator\n",
        "                # ---------------------\n",
        "\n",
        "                # Select a random batch\n",
        "                idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "                imgs = X_train[idx]\n",
        "                # Sample generator input\n",
        "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "                # Train the critic\n",
        "                d_loss = self.critic_model.train_on_batch([imgs, noise],\n",
        "                                                                [valid, fake, dummy])\n",
        "\n",
        "            # ---------------------\n",
        "            #  Train Generator\n",
        "            # ---------------------\n",
        "\n",
        "            g_loss = self.generator_model.train_on_batch(noise, valid)\n",
        "\n",
        "            # Plot the progress\n",
        "            print (\"%d [D loss: %f] [G loss: %f]\" % (epoch, d_loss[0], g_loss))\n",
        "\n",
        "            # If at save interval => save generated image samples\n",
        "            #if epoch % sample_interval == 0:\n",
        "                #self.sample_images(epoch)\n",
        "\n",
        "    def sample_images(self, epoch):\n",
        "        r, c = 5, 5\n",
        "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
        "        gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "        # Rescale images 0 - 1\n",
        "        #gen_imgs = 0.5 * gen_imgs + 1\n",
        "\n",
        "        #fig, axs = plt.subplots(r, c)\n",
        "        #cnt = 0\n",
        "        #for i in range(r):\n",
        "            #for j in range(c):\n",
        "                #axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "                #axs[i,j].axis('off')\n",
        "               # cnt += 1\n",
        "        #fig.savefig(\"images/mnist_%d.png\" % epoch)\n",
        "        #plt.close()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    wgan = WGANGP()\n",
        "    wgan.train(epochs=300, batch_size=(64))"
      ],
      "execution_count": 301,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_236 (Dense)            (None, 100)               5100      \n",
            "_________________________________________________________________\n",
            "batch_normalization_515 (Bat (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_517 (LeakyReLU)  (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "reshape_92 (Reshape)         (None, 100, 1)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_309 (Conv1D)          (None, 100, 32)           128       \n",
            "_________________________________________________________________\n",
            "batch_normalization_516 (Bat (None, 100, 32)           128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_518 (LeakyReLU)  (None, 100, 32)           0         \n",
            "_________________________________________________________________\n",
            "up_sampling1d_139 (UpSamplin (None, 200, 32)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_310 (Conv1D)          (None, 200, 32)           3104      \n",
            "_________________________________________________________________\n",
            "batch_normalization_517 (Bat (None, 200, 32)           128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_519 (LeakyReLU)  (None, 200, 32)           0         \n",
            "_________________________________________________________________\n",
            "up_sampling1d_140 (UpSamplin (None, 400, 32)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_311 (Conv1D)          (None, 400, 32)           3104      \n",
            "_________________________________________________________________\n",
            "batch_normalization_518 (Bat (None, 400, 32)           128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_520 (LeakyReLU)  (None, 400, 32)           0         \n",
            "_________________________________________________________________\n",
            "up_sampling1d_141 (UpSamplin (None, 800, 32)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_312 (Conv1D)          (None, 800, 32)           3104      \n",
            "_________________________________________________________________\n",
            "batch_normalization_519 (Bat (None, 800, 32)           128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_521 (LeakyReLU)  (None, 800, 32)           0         \n",
            "_________________________________________________________________\n",
            "flatten_77 (Flatten)         (None, 25600)             0         \n",
            "_________________________________________________________________\n",
            "dense_237 (Dense)            (None, 100)               2560100   \n",
            "_________________________________________________________________\n",
            "batch_normalization_520 (Bat (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_522 (LeakyReLU)  (None, 100)               0         \n",
            "=================================================================\n",
            "Total params: 2,575,952\n",
            "Trainable params: 2,575,296\n",
            "Non-trainable params: 656\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_93 (Reshape)         (None, 99, 30)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_313 (Conv1D)          (None, 99, 32)            2912      \n",
            "_________________________________________________________________\n",
            "batch_normalization_521 (Bat (None, 99, 32)            128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_523 (LeakyReLU)  (None, 99, 32)            0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_106 (MaxPoolin (None, 49, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_314 (Conv1D)          (None, 49, 32)            3104      \n",
            "_________________________________________________________________\n",
            "batch_normalization_522 (Bat (None, 49, 32)            128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_524 (LeakyReLU)  (None, 49, 32)            0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_107 (MaxPoolin (None, 24, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_315 (Conv1D)          (None, 24, 32)            3104      \n",
            "_________________________________________________________________\n",
            "batch_normalization_523 (Bat (None, 24, 32)            128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_525 (LeakyReLU)  (None, 24, 32)            0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_108 (MaxPoolin (None, 12, 32)            0         \n",
            "_________________________________________________________________\n",
            "flatten_78 (Flatten)         (None, 384)               0         \n",
            "_________________________________________________________________\n",
            "dense_238 (Dense)            (None, 50)                19250     \n",
            "_________________________________________________________________\n",
            "batch_normalization_524 (Bat (None, 50)                200       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_526 (LeakyReLU)  (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_239 (Dense)            (None, 15)                765       \n",
            "_________________________________________________________________\n",
            "batch_normalization_525 (Bat (None, 15)                60        \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_527 (LeakyReLU)  (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "dense_240 (Dense)            (None, 1)                 16        \n",
            "_________________________________________________________________\n",
            "batch_normalization_526 (Bat (None, 1)                 4         \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_528 (LeakyReLU)  (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 29,799\n",
            "Trainable params: 29,475\n",
            "Non-trainable params: 324\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-301-627ace4563b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m     \u001b[0mwgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWGANGP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m     \u001b[0mwgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-301-627ace4563b8>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# Discriminator determines validity of the real and fake images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_tensor_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             \u001b[0moutput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_internal_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mrun_internal_graph\u001b[0;34m(self, inputs, masks)\u001b[0m\n\u001b[1;32m    719\u001b[0m                                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputed_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                             output_tensors = to_list(\n\u001b[0;32m--> 721\u001b[0;31m                                 layer.call(computed_tensor, **kwargs))\n\u001b[0m\u001b[1;32m    722\u001b[0m                             output_masks = layer.compute_mask(computed_tensor,\n\u001b[1;32m    723\u001b[0m                                                               computed_mask)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_tensor_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             \u001b[0moutput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_internal_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mrun_internal_graph\u001b[0;34m(self, inputs, masks)\u001b[0m\n\u001b[1;32m    777\u001b[0m                         input_shapes = unpack_singleton(\n\u001b[1;32m    778\u001b[0m                             [x._keras_shape for x in computed_tensors])\n\u001b[0;32m--> 779\u001b[0;31m                         \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                         uses_learning_phase = any(\n\u001b[1;32m    781\u001b[0m                             [x._uses_learning_phase for x in computed_tensors])\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mcompute_output_shape\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;31m# input shape known? then we can compute the output shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             return (input_shape[0],) + self._fix_unknown_dimension(\n\u001b[0;32m--> 398\u001b[0;31m                 input_shape[1:], self.target_shape)\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/core.py\u001b[0m in \u001b[0;36m_fix_unknown_dimension\u001b[0;34m(self, input_shape, output_shape)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0moutput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munknown\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mknown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mknown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: total size of new array must be unchanged"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddfbO9OFOTg3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}